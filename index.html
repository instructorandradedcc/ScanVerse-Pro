<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>ScanVerse | Real CV Processing</title>
    
    <!-- React & ReactDOM -->
    <script crossorigin src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    
    <!-- Babel -->
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/examples/js/controls/OrbitControls.js"></script>
    
    <!-- Lucide Icons -->
    <script src="https://unpkg.com/lucide@latest"></script>

    <!-- OpenCV.js (Visión por Computadora Real) -->
    <script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="window.cvLoaded=true"></script>

    <style>
        body { margin: 0; overflow: hidden; background-color: #0f172a; font-family: 'Inter', sans-serif; }
        canvas { display: block; }
        .lidar-grid {
            background-image: linear-gradient(rgba(0, 255, 170, 0.1) 1px, transparent 1px),
            linear-gradient(90deg, rgba(0, 255, 170, 0.1) 1px, transparent 1px);
            background-size: 40px 40px;
        }
        .scanner-line {
            position: absolute; left: 0; width: 100%; height: 2px; background: #00ffaa;
            box-shadow: 0 0 10px #00ffaa; animation: scanline 3s linear infinite;
        }
        @keyframes scanline { 0% { top: 0%; opacity: 0; } 10% { opacity: 1; } 90% { opacity: 1; } 100% { top: 100%; opacity: 0; } }
        /* Ocultar scrollbar */
        ::-webkit-scrollbar { width: 0px; background: transparent; }
    </style>
</head>
<body>

<div id="root"></div>

<script type="text/babel">

const { useState, useEffect, useRef } = React;

// --- UTILS: Computer Vision ---

// Función para procesar imagen real con OpenCV
const processImageToPoints = async (imgElement, index, totalImages) => {
    return new Promise((resolve) => {
        if (!window.cv || !window.cvLoaded) {
            console.warn("OpenCV aun no carga, simulando...");
            resolve([]); 
            return;
        }

        // 1. Leer imagen desde el elemento DOM
        const src = cv.imread(imgElement);
        const gray = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

        // 2. Detectar características (ORB es rápido y bueno para web)
        const orb = new cv.ORB(500); // Detectar 500 puntos por foto
        const keypoints = new cv.KeyPointVector();
        const descriptors = new cv.Mat();
        orb.detectAndCompute(gray, new cv.Mat(), keypoints, descriptors);

        // 3. Extraer datos (X, Y, Color)
        const points = [];
        const width = src.cols;
        const height = src.rows;
        
        // Calcular ángulo base para esta foto (asumiendo panorama 360)
        const anglePerImage = (Math.PI * 2) / totalImages;
        const baseAngle = index * anglePerImage;

        for (let i = 0; i < keypoints.size(); i++) {
            const kp = keypoints.get(i);
            const x = kp.pt.x;
            const y = kp.pt.y;

            // Obtener color del pixel original
            // cv.Mat data es un array plano. RGBA son 4 canales.
            // pos = y * width * 4 + x * 4
            const row = Math.floor(y);
            const col = Math.floor(x);
            // Acceso seguro a memoria
            if(row < height && col < width){
                const pixel = src.ucharPtr(row, col); // [R, G, B, A]
                
                // --- MATEMÁTICA DE PROYECCIÓN ---
                // Convertimos 2D (foto) a 3D (Cilindro alrededor del usuario)
                
                // Mapear X de la imagen a un ángulo dentro del "slice" de la foto
                // Normalizar X de 0 a 1
                const u = x / width; 
                // Ángulo final = Ángulo base de la foto + (u * FOV de la cámara aprox 60 grados)
                // Ajustamos para que se cosan suavemente
                const theta = baseAngle - (u * (Math.PI / 3)) + Math.PI; 

                // Mapear Y a altura
                const v = (y / height) - 0.5; // Centrar en 0
                const h = -v * 3; // Escalar altura

                const radius = 4; // Radio de la habitación
                
                // Coordenadas Polares a Cartesianas
                const pX = radius * Math.sin(theta);
                const pZ = radius * Math.cos(theta);
                const pY = h;

                points.push({
                    pos: [pX, pY, pZ],
                    color: [pixel[0]/255, pixel[1]/255, pixel[2]/255]
                });
            }
        }

        // Limpiar memoria de OpenCV (Crítico en JS)
        src.delete(); gray.delete(); orb.delete(); keypoints.delete(); descriptors.delete();
        
        resolve(points);
    });
};

// --- COMPONENTES ---

const Icon = ({ name, size = 24, className }) => {
    useEffect(() => lucide.createIcons(), [name]);
    return <i data-lucide={name} width={size} height={size} className={className}></i>;
};

// Pantalla 1: Inicio
const HomeScreen = ({ onStart }) => (
    <div className="h-screen w-full flex flex-col items-center justify-center bg-slate-900 text-white p-6 relative overflow-hidden">
        <div className="absolute inset-0 lidar-grid opacity-20 pointer-events-none"></div>
        <div className="z-10 text-center max-w-md">
            <div className="w-24 h-24 bg-emerald-500/10 rounded-full flex items-center justify-center ring-1 ring-emerald-500/50 mx-auto mb-6">
                <Icon name="scan-face" size={48} className="text-emerald-400" />
            </div>
            <h1 className="text-4xl font-bold mb-2 bg-clip-text text-transparent bg-gradient-to-r from-emerald-400 to-blue-500">ScanVerse Pro</h1>
            <p className="text-slate-400 mb-8 text-sm">Motor de Fotogrametría Web.<br/>Detecta características reales usando OpenCV.</p>
            <button onClick={onStart} className="w-full py-4 bg-emerald-600 hover:bg-emerald-500 rounded-xl font-bold shadow-lg shadow-emerald-900/50 transition flex items-center justify-center gap-2">
                <Icon name="camera" size={20} /> INICIAR ESCANEO
            </button>
        </div>
    </div>
);

// Pantalla 2: Cámara (Captura Real)
const CaptureScreen = ({ onProcess, onBack }) => {
    const videoRef = useRef(null);
    const canvasRef = useRef(null); // Para capturar el frame
    const [photos, setPhotos] = useState([]);
    const [stream, setStream] = useState(null);

    useEffect(() => {
        navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } })
            .then(s => {
                setStream(s);
                if(videoRef.current) videoRef.current.srcObject = s;
            })
            .catch(e => console.error("Sin cámara", e));
        return () => { if(stream) stream.getTracks().forEach(t => t.stop()); }
    }, []);

    const takePhoto = () => {
        if(!videoRef.current || !canvasRef.current) return;
        
        const vid = videoRef.current;
        const canvas = canvasRef.current;
        canvas.width = vid.videoWidth / 4; // Reducir res para rendimiento
        canvas.height = vid.videoHeight / 4;
        
        const ctx = canvas.getContext('2d');
        ctx.drawImage(vid, 0, 0, canvas.width, canvas.height);
        
        // Guardar imagen como Data URL
        const dataUrl = canvas.toDataURL('image/jpeg', 0.8);
        setPhotos(prev => [...prev, dataUrl]);
    };

    return (
        <div className="h-screen bg-black flex flex-col relative">
            <video ref={videoRef} autoPlay playsInline muted className="flex-1 object-cover opacity-80" />
            <canvas ref={canvasRef} className="hidden" />
            
            {/* Overlay Guía */}
            <div className="absolute inset-0 pointer-events-none flex items-center justify-center">
                <div className="w-64 h-64 border border-white/30 rounded-lg relative">
                    <div className="absolute top-0 left-0 w-4 h-4 border-t-2 border-l-2 border-emerald-400"></div>
                    <div className="absolute top-0 right-0 w-4 h-4 border-t-2 border-r-2 border-emerald-400"></div>
                    <div className="absolute bottom-0 left-0 w-4 h-4 border-b-2 border-l-2 border-emerald-400"></div>
                    <div className="absolute bottom-0 right-0 w-4 h-4 border-b-2 border-r-2 border-emerald-400"></div>
                    <div className="scanner-line opacity-50"></div>
                </div>
                <div className="absolute top-8 bg-black/50 px-3 py-1 rounded-full text-xs text-emerald-400 backdrop-blur">
                    Gira lentamente en círculo
                </div>
            </div>

            <div className="h-32 bg-slate-900/90 backdrop-blur flex items-center justify-around pb-4">
                <button onClick={onBack} className="p-3 bg-slate-800 rounded-full text-white"><Icon name="x" /></button>
                <button onClick={takePhoto} className="w-16 h-16 bg-white rounded-full border-4 border-slate-300 active:scale-90 transition"></button>
                <button 
                    onClick={() => photos.length > 0 && onProcess(photos)} 
                    className={`p-3 rounded-full text-white ${photos.length>0 ? 'bg-emerald-500' : 'bg-slate-700 opacity-50'}`}
                >
                    <Icon name="arrow-right" />
                </button>
            </div>
            <div className="absolute bottom-36 left-4 flex gap-2 overflow-x-auto max-w-full p-2">
                {photos.map((p, i) => <img key={i} src={p} className="w-12 h-16 object-cover rounded border border-white/50" />)}
            </div>
        </div>
    );
};

// Pantalla 3: Procesamiento REAL con OpenCV
const ProcessingScreen = ({ photos, onComplete }) => {
    const [status, setStatus] = useState("Cargando motor CV...");
    const [progress, setProgress] = useState(0);
    const [currentImg, setCurrentImg] = useState(null);
    const [debugPoints, setDebugPoints] = useState(0);
    const imgRef = useRef(null);

    useEffect(() => {
        const processAll = async () => {
            // Esperar a que OpenCV cargue
            let checks = 0;
            while(!window.cvLoaded && checks < 20) {
                await new Promise(r => setTimeout(r, 500));
                checks++;
            }
            if(!window.cv) {
                alert("Error cargando librería de visión.");
                onComplete([]);
                return;
            }

            let allPoints = [];
            
            for (let i = 0; i < photos.length; i++) {
                setStatus(`Analizando imagen ${i + 1}/${photos.length}...`);
                setCurrentImg(photos[i]);
                setProgress(((i) / photos.length) * 100);
                
                // Pequeña pausa para renderizar la imagen en el DOM oculto antes de leerla
                await new Promise(r => setTimeout(r, 100));
                
                if(imgRef.current) {
                    const points = await processImageToPoints(imgRef.current, i, photos.length);
                    setDebugPoints(prev => prev + points.length);
                    allPoints = [...allPoints, ...points];
                }
            }

            setStatus("Generando nube de puntos...");
            setProgress(100);
            setTimeout(() => onComplete(allPoints), 1000);
        };
        
        processAll();
    }, [photos]);

    return (
        <div className="h-screen bg-slate-900 text-white flex flex-col items-center justify-center p-6">
            {/* Imagen oculta/visible para debug visual del usuario */}
            <div className="relative w-64 h-64 mb-8 bg-black rounded-lg overflow-hidden border border-slate-700 shadow-2xl">
                {currentImg && (
                    <>
                    <img ref={imgRef} src={currentImg} className="w-full h-full object-cover opacity-50" crossOrigin="anonymous" />
                    <div className="absolute inset-0 flex items-center justify-center">
                         <div className="w-full h-0.5 bg-green-500 absolute top-1/2 animate-pulse"></div>
                         <div className="h-full w-0.5 bg-green-500 absolute left-1/2 animate-pulse"></div>
                    </div>
                    {/* Efecto de puntos detectados */}
                    <div className="absolute inset-0 flex flex-wrap content-center justify-center gap-4 opacity-50">
                        <div className="w-2 h-2 bg-green-400 rounded-full animate-ping"></div>
                        <div className="w-2 h-2 bg-green-400 rounded-full animate-ping" style={{animationDelay:'0.2s'}}></div>
                        <div className="w-2 h-2 bg-green-400 rounded-full animate-ping" style={{animationDelay:'0.5s'}}></div>
                    </div>
                    </>
                )}
            </div>

            <h2 className="text-xl font-bold font-mono text-emerald-400">{status}</h2>
            <div className="w-64 h-2 bg-slate-700 rounded-full mt-4 overflow-hidden">
                <div className="h-full bg-emerald-500 transition-all duration-300" style={{width: `${progress}%`}}></div>
            </div>
            
            <div className="mt-8 grid grid-cols-2 gap-8 text-center text-xs text-slate-400 font-mono">
                <div>
                    <div className="text-white text-lg">{debugPoints}</div>
                    <div>PUNTOS CLAVE</div>
                </div>
                <div>
                    <div className="text-white text-lg">ORB</div>
                    <div>ALGORITMO</div>
                </div>
            </div>
        </div>
    );
};

// Pantalla 4: Visor 3D de Datos Reales
const Viewer3D = ({ pointCloudData, onReset }) => {
    const mountRef = useRef(null);

    useEffect(() => {
        if (!mountRef.current) return;
        const width = mountRef.current.clientWidth;
        const height = mountRef.current.clientHeight;
        
        // Scene Setup
        const scene = new THREE.Scene();
        scene.background = new THREE.Color(0x050505);

        const camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);
        camera.position.set(0, 0, 0.1); // Centro (donde estaba el usuario)

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(width, height);
        mountRef.current.appendChild(renderer.domElement);

        const controls = new THREE.OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.rotateSpeed = -0.5; // Invertir para sentir que miras alrededor

        // --- CREAR NUBE DE PUNTOS REAL ---
        if(pointCloudData && pointCloudData.length > 0) {
            const geometry = new THREE.BufferGeometry();
            const positions = [];
            const colors = [];

            pointCloudData.forEach(pt => {
                positions.push(...pt.pos);
                colors.push(...pt.color);
            });

            geometry.setAttribute('position', new THREE.Float32BufferAttribute(positions, 3));
            geometry.setAttribute('color', new THREE.Float32BufferAttribute(colors, 3));

            const material = new THREE.PointsMaterial({ 
                size: 0.08, 
                vertexColors: true,
                transparent: true,
                opacity: 0.9,
                sizeAttenuation: true
            });

            const particles = new THREE.Points(geometry, material);
            scene.add(particles);
        } else {
            // Fallback si no hay puntos (ej: opencv falló)
            const geo = new THREE.TorusGeometry(3, 1, 16, 100);
            const mat = new THREE.PointsMaterial({ color: 'red', size: 0.1 });
            scene.add(new THREE.Points(geo, mat));
        }

        // Helpers
        const grid = new THREE.GridHelper(10, 10, 0x333333, 0x111111);
        grid.position.y = -2;
        scene.add(grid);

        const animate = () => {
            requestAnimationFrame(animate);
            controls.update();
            renderer.render(scene, camera);
        };
        animate();

        return () => { 
            if(mountRef.current) mountRef.current.innerHTML = ''; 
        };
    }, [pointCloudData]);

    return (
        <div className="h-screen relative">
            <div ref={mountRef} className="w-full h-full cursor-move" />
            
            <div className="absolute top-4 left-4 bg-black/70 text-white p-4 rounded-lg backdrop-blur pointer-events-none">
                <h1 className="font-bold text-emerald-400 text-lg">Reconstrucción CV</h1>
                <p className="text-xs text-slate-300">
                    Puntos Renderizados: {pointCloudData.length}<br/>
                    Algoritmo: Sparse Point Cloud Projection
                </p>
            </div>
            
            <button onClick={onReset} className="absolute bottom-8 left-1/2 -translate-x-1/2 bg-slate-800 text-white px-6 py-3 rounded-full shadow-lg border border-slate-600 font-bold hover:bg-slate-700">
                NUEVO ESCANEO
            </button>
        </div>
    );
};

// --- APP ROOT ---
const App = () => {
    const [step, setStep] = useState('home');
    const [capturedPhotos, setCapturedPhotos] = useState([]);
    const [points, setPoints] = useState([]);

    return (
        <>
            {step === 'home' && <HomeScreen onStart={() => setStep('capture')} />}
            
            {step === 'capture' && (
                <CaptureScreen 
                    onBack={() => setStep('home')}
                    onProcess={(photos) => {
                        setCapturedPhotos(photos);
                        setStep('process');
                    }} 
                />
            )}

            {step === 'process' && (
                <ProcessingScreen 
                    photos={capturedPhotos} 
                    onComplete={(data) => {
                        setPoints(data);
                        setStep('view');
                    }} 
                />
            )}

            {step === 'view' && <Viewer3D pointCloudData={points} onReset={() => setStep('home')} />}
        </>
    );
};

const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(<App />);

</script>
</body>
</html>